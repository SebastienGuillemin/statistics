{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0732f1-e14a-4518-b69a-b13de28a9f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import load_samples_dataset, quanti_cols_df_names, quali_cols_df_names\n",
    "from samples_dataset import SamplesDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import math\n",
    "import shap\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib widget\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa7072",
   "metadata": {},
   "source": [
    "# Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead53253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, n_epoch=10, verbose=False):\n",
    "    device = next(model.parameters()).device\n",
    "    mean_loss = []\n",
    "    nb_examples = len(dataloader.dataset)\n",
    "\n",
    "    model.train(True)\n",
    "    pbar = tqdm(range(n_epoch), bar_format='{percentage:3.0f}%{bar}{n_fmt}/{total_fmt} epoch(s) [{elapsed}<{remaining}, {rate_fmt}{postfix}]')\n",
    "    for epoch in pbar:  # loop over the dataset multiple times\n",
    "        loss_sum = 0.0\n",
    "        for i, data in enumerate(dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)[:,0]\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "        mean_loss.append(loss_sum / nb_examples)\n",
    "\n",
    "    if verbose:\n",
    "        print('Finished Training')\n",
    "        plt.title('Mean error for each epoch')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Mean error')\n",
    "        plt.plot(range(1, n_epoch + 1), mean_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f3adbc",
   "metadata": {},
   "source": [
    "# Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc9b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_dataloader(model, dataloader, verbose=False):\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    model.eval()    \n",
    "    with torch.no_grad():\n",
    "        accuracy = 0.0\n",
    "        nb_examples = 0.0\n",
    "        for i, data in enumerate(dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            nb_examples += len(inputs)\n",
    "\n",
    "            outputs = model(inputs)[:,0]\n",
    "            outputs = (outputs >= threshold).float()\n",
    "            accuracy += torch.sum(outputs == labels).item()\n",
    "\n",
    "        accuracy /= nb_examples\n",
    "        return accuracy * 100\n",
    "\n",
    "def test_X_y(model, X, y, verbose=False):\n",
    "    samples_test = SamplesDataset()\n",
    "    samples_test.add_examples(X, y)\n",
    "    dataloader = DataLoader(samples_test, batch_size=64, shuffle=True, pin_memory=True)\n",
    "    \n",
    "    return test_with_dataloader(model, dataloader, verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6518fa50",
   "metadata": {},
   "source": [
    "# Predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2c6e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "    device = next(model.parameters()).device\n",
    "    X = torch.Tensor(torch.Tensor(X))\n",
    "    X = X.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    results = model(X)\n",
    "    results = (results >= threshold).cpu().float().numpy()\n",
    "    return torch.from_numpy(results).T[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0bccf",
   "metadata": {},
   "source": [
    "# Cross-validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d789bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_valisation(model, X, y, optimizer, criterion, k=10, n_epoch=50):\n",
    "    accuracies = list()\n",
    "\n",
    "    if len(X) != len(y):\n",
    "            raise Exception(f'The size of X {len(X)} must be the same as the size y {len(y)}.')\n",
    "    \n",
    "    dataset_X_folds = np.array_split(X, k)\n",
    "    dataset_y_folds = np.array_split(y, k)\n",
    "\n",
    "    print(f'Starting {k}-fold cross-validation.')\n",
    "    pbar = tqdm(range(k), bar_format='Cross-validation performed at {percentage:3.0f}%{bar}{r_bar}')\n",
    "    for i in pbar:\n",
    "        samples_train = SamplesDataset()\n",
    "        dataset_X_train = np.concatenate(dataset_X_folds[0:i] + dataset_X_folds[i+1: len(dataset_X_folds)])\n",
    "        dataset_y_train = np.concatenate(dataset_y_folds[0:i] + dataset_y_folds[i+1: len(dataset_y_folds)])\n",
    "        samples_train.add_examples(dataset_X_train, dataset_y_train)\n",
    "\n",
    "        samples_test = SamplesDataset()\n",
    "        dataset_X_test = dataset_X_folds[i]\n",
    "        dataset_y_test = dataset_y_folds[i]\n",
    "        samples_test.add_examples(dataset_X_test, dataset_y_test)\n",
    "\n",
    "        train_dataloader = DataLoader(samples_train, batch_size=64, shuffle=True, pin_memory=True)\n",
    "        test_dataloader = DataLoader(samples_test, batch_size=64, shuffle=True, pin_memory=True)\n",
    "\n",
    "        train(model=model, dataloader=train_dataloader, optimizer=optimizer, criterion=criterion, n_epoch=n_epoch)\n",
    "        accuracy = test_with_dataloader(model=model, dataloader=test_dataloader)\n",
    "\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    return np.array(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277d03f",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d83dfc",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee55ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = load_samples_dataset(export_as_csv=True, from_csv=False)\n",
    "X, y = full_dataset.get_row_dataset()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    "\n",
    "print(f'Training examples count : {len(X_train)}.')\n",
    "print(f'Testing examples count : {len(X_test)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.matrix(X_train)\n",
    "matrix = matrix\n",
    "print(f'Matrix shape : {matrix.shape}.')\n",
    "\n",
    "bin_matrix = matrix.copy()\n",
    "bin_matrix[bin_matrix > 0] = 1\n",
    "\n",
    "plot_matrix = bin_matrix[:500,:].T\n",
    "\n",
    "matfig = plt.figure(figsize=(20,4))\n",
    "plt.matshow(plot_matrix, fignum=matfig.number)\n",
    "plt.title('Subset of instances')\n",
    "plt.xlabel('Instances')\n",
    "plt.ylabel('Instances variables')\n",
    "plt.show()\n",
    "\n",
    "sparsisty = np.count_nonzero(matrix == 0) / matrix.size\n",
    "print(f'Matrix is {100 * sparsisty:3.2f}% sparse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b05377",
   "metadata": {},
   "source": [
    "## Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28281840",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "\n",
    "n_input = len(X_train[0])\n",
    "n_hidden_1 = math.floor(n_input / 3)\n",
    "n_hidden_2 = math.floor(n_hidden_1 / 3)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_input, n_hidden_1),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(n_hidden_1, n_hidden_2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(n_hidden_2, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "model = model.float()\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print(f'Model: {model}')\n",
    "print(f'Model on device : {next(model.parameters()).device}.')\n",
    "\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a831f4cc",
   "metadata": {},
   "source": [
    "## Perfoming cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd0a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7\n",
    "accuracies = cross_valisation(model=model, X=X_train, y=y_train, optimizer=optimizer, criterion=criterion, k=k, n_epoch=20)\n",
    "print(f'Accuracy mean : {accuracies.mean()}')\n",
    "print(f'Accuracy standard deviation : {accuracies.std()}')\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Accuracy for each cross-validation iteration')\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Score')\n",
    "plt.plot(range(1, k + 1), accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42381425",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(model=model, X=X_test)\n",
    "y_test_tensor = torch.Tensor([y_test])[0]\n",
    "\n",
    "# Accuracy\n",
    "pred_accuracy = torch.sum(y_pred == y_test_tensor).item() / len(y_test) * 100\n",
    "print(f'Test acuracy : {pred_accuracy:0.2f}%.')\n",
    "\n",
    "# Confusion matrix\n",
    "display = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    normalize='true',\n",
    "    display_labels=np.asarray(['Non proches', 'Proches']),\n",
    "    cmap=plt.cm.BuGn)\n",
    "display.ax_.set_title('Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34a2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrap = lambda data : model(torch.from_numpy(data))\n",
    "X_test_tensor = torch.Tensor(torch.Tensor(X_test)).to(device)\n",
    "\n",
    "explainer = shap.DeepExplainer(model=model, data=X_test_tensor)\n",
    "shap_val = explainer.shap_values(X_test_tensor[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a58970",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = full_dataset.get_columns_names()\n",
    "\n",
    "shap_values_df = pd.DataFrame(shap_val, columns = full_dataset.get_columns_names())\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Shapley values')\n",
    "shap.summary_plot(shap_val, features=shap_values_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a0c8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
