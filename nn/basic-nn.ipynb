{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc0732f1-e14a-4518-b69a-b13de28a9f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import get_dataloaders, load_samples_dataset\n",
    "from samples_dataset import SamplesDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa7072",
   "metadata": {},
   "source": [
    "# Train method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead53253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, n_epoch=10, verbose=False):\n",
    "    device = next(model.parameters()).device\n",
    "    mean_loss = []\n",
    "    nb_examples = len(dataloader.dataset)\n",
    "\n",
    "    model.train(True)\n",
    "    for epoch in tqdm(range(n_epoch)):  # loop over the dataset multiple times\n",
    "        loss_sum = 0.0\n",
    "        for i, data in enumerate(dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)[:,0]\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "        mean_loss.append(loss_sum / nb_examples)\n",
    "\n",
    "    if verbose:\n",
    "        print('Finished Training')\n",
    "        plt.title('Mean error for each epoch')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Mean error')\n",
    "        plt.plot(range(1, n_epoch + 1), mean_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f3adbc",
   "metadata": {},
   "source": [
    "# Test method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbc9b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, verbose=False):\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        accuracy = 0.0\n",
    "        nb_examples = 0.0\n",
    "        for i, data in enumerate(dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            nb_examples += len(inputs)\n",
    "\n",
    "            outputs = model(inputs)[:,0]\n",
    "            accuracy += torch.sum(outputs == labels).item()\n",
    "            \n",
    "        accuracy /= nb_examples\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0bccf",
   "metadata": {},
   "source": [
    "# Cross-validation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d789bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_valisation(model, X, y, optimizer, criterion, k=10, n_epoch=50):\n",
    "    scores = list()\n",
    "\n",
    "    if len(X) != len(y):\n",
    "            raise Exception(f'The size of X {len(X)} must be the same as the size y {len(y)}.')\n",
    "    \n",
    "    dataset_X_folds = np.array_split(X, k)\n",
    "    dataset_y_folds = np.array_split(y, k)\n",
    "\n",
    "    print(f'Satrting {k}-fold cross-validation.')\n",
    "    pbar = tqdm(range(k), bar_format='Cross-validation performed at {percentage}%{bar}{r_bar}')\n",
    "    for i in pbar:\n",
    "        samples_train = SamplesDataset()\n",
    "        dataset_X_train = np.concatenate(dataset_X_folds[0:i] + dataset_X_folds[i+1: len(dataset_X_folds)])\n",
    "        dataset_y_train = np.concatenate(dataset_y_folds[0:i] + dataset_y_folds[i+1: len(dataset_y_folds)])\n",
    "        samples_train.add_examples(dataset_X_train, dataset_y_train)\n",
    "\n",
    "        samples_test = SamplesDataset()\n",
    "        dataset_X_test = dataset_X_folds[i]\n",
    "        dataset_y_test = dataset_y_folds[i]\n",
    "        samples_test.add_examples(dataset_X_test, dataset_y_test)\n",
    "\n",
    "        train_dataloader = DataLoader(samples_train, batch_size=64, shuffle=True, pin_memory=True)\n",
    "        test_dataloader = DataLoader(samples_test, batch_size=64, shuffle=True, pin_memory=True)\n",
    "\n",
    "        train(model=model, dataloader=train_dataloader, optimizer=optimizer, criterion=criterion, n_epoch=n_epoch)\n",
    "        score = test(model=model, dataloader=test_dataloader)\n",
    "\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277d03f",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b05377",
   "metadata": {},
   "source": [
    "## Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28281840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Sequential(\n",
      "  (0): Linear(in_features=70, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=100, out_features=1, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n",
      "Model on device : cpu.\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "\n",
    "n_hidden = 100\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(70, n_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(n_hidden, n_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(n_hidden, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print(f'Model: {model}')\n",
    "print(f'Model on device : {next(model.parameters()).device}.')\n",
    "\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d83dfc",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee55ce96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating positive examples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145131f3e4004e8b92a5338a3ba1f517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/649 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating negative examples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d18f0c71b04c4ba21fbbf4abb4dbf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size : 14652\n"
     ]
    }
   ],
   "source": [
    "full_dataset = load_samples_dataset()\n",
    "full_dataset.shuffle()\n",
    "dataset_X, dataset_y = full_dataset.get_row_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a831f4cc",
   "metadata": {},
   "source": [
    "## Perfoming cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cd0a135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satrting 2-fold cross-validation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfc39712de54b1d9748cdb6cd22bb7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cross-validation performed at 0.0%\n",
       "          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603317fd387642f6942a123d2dbd7fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9188c5abc450443b95a5ba73e22f74c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score mean : 0.36534261534261536\n",
      "Score standard deviation : 0.0014332514332514312\n"
     ]
    }
   ],
   "source": [
    "score = cross_valisation(model=model, X=dataset_X, y=dataset_y, optimizer=optimizer, criterion=criterion, k=2, n_epoch=20)\n",
    "print(f'Score mean : {score.mean()}')\n",
    "print(f'Score standard deviation : {score.std()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
