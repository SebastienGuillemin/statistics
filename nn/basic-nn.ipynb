{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0732f1-e14a-4518-b69a-b13de28a9f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import load_samples_dataset\n",
    "from samples_dataset import SamplesDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "\n",
    "%matplotlib widget\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "threshold = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa7072",
   "metadata": {},
   "source": [
    "# Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead53253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, n_epoch=10, verbose=False):\n",
    "    device = next(model.parameters()).device\n",
    "    mean_loss = []\n",
    "    nb_examples = len(dataloader.dataset)\n",
    "\n",
    "    model.train(True)\n",
    "    for epoch in tqdm(range(n_epoch)):  # loop over the dataset multiple times\n",
    "        loss_sum = 0.0\n",
    "        for i, data in enumerate(dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)[:,0]\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "        mean_loss.append(loss_sum / nb_examples)\n",
    "\n",
    "    if verbose:\n",
    "        print('Finished Training')\n",
    "        plt.title('Mean error for each epoch')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Mean error')\n",
    "        plt.plot(range(1, n_epoch + 1), mean_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f3adbc",
   "metadata": {},
   "source": [
    "# Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc9b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_dataloader(model, dataloader, verbose=False):\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    model.eval()    \n",
    "    with torch.no_grad():\n",
    "        accuracy = 0.0\n",
    "        nb_examples = 0.0\n",
    "        for i, data in enumerate(dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            nb_examples += len(inputs)\n",
    "\n",
    "            outputs = model(inputs)[:,0]\n",
    "            outputs = (outputs > threshold).float()\n",
    "            accuracy += torch.sum(outputs == labels).item()\n",
    "\n",
    "        accuracy /= nb_examples\n",
    "        return accuracy * 100\n",
    "\n",
    "def test_X_y(model, X, y, verbose=False):\n",
    "    samples_test = SamplesDataset()\n",
    "    samples_test.add_examples(X, y)\n",
    "    dataloader = DataLoader(samples_test, batch_size=64, shuffle=True, pin_memory=True)\n",
    "    \n",
    "    return test_with_dataloader(model, dataloader, verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6518fa50",
   "metadata": {},
   "source": [
    "# Predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2c6e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "    X = np.array(X)\n",
    "    device = next(model.parameters()).device\n",
    "    X = torch.Tensor(torch.Tensor(X))\n",
    "    X = X.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    results = model(X)\n",
    "    results = (results > threshold).float().numpy()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0bccf",
   "metadata": {},
   "source": [
    "# Cross-validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d789bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_valisation(model, X, y, optimizer, criterion, k=10, n_epoch=50):\n",
    "    accuracies = list()\n",
    "\n",
    "    if len(X) != len(y):\n",
    "            raise Exception(f'The size of X {len(X)} must be the same as the size y {len(y)}.')\n",
    "    \n",
    "    dataset_X_folds = np.array_split(X, k)\n",
    "    dataset_y_folds = np.array_split(y, k)\n",
    "\n",
    "    print(f'Starting {k}-fold cross-validation.')\n",
    "    pbar = tqdm(range(k), bar_format='Cross-validation performed at {percentage:3.0f}%{bar}{r_bar}')\n",
    "    for i in pbar:\n",
    "        samples_train = SamplesDataset()\n",
    "        dataset_X_train = np.concatenate(dataset_X_folds[0:i] + dataset_X_folds[i+1: len(dataset_X_folds)])\n",
    "        dataset_y_train = np.concatenate(dataset_y_folds[0:i] + dataset_y_folds[i+1: len(dataset_y_folds)])\n",
    "        samples_train.add_examples(dataset_X_train, dataset_y_train)\n",
    "\n",
    "        samples_test = SamplesDataset()\n",
    "        dataset_X_test = dataset_X_folds[i]\n",
    "        dataset_y_test = dataset_y_folds[i]\n",
    "        samples_test.add_examples(dataset_X_test, dataset_y_test)\n",
    "\n",
    "        train_dataloader = DataLoader(samples_train, batch_size=64, shuffle=True, pin_memory=True)\n",
    "        test_dataloader = DataLoader(samples_test, batch_size=64, shuffle=True, pin_memory=True)\n",
    "\n",
    "        train(model=model, dataloader=train_dataloader, optimizer=optimizer, criterion=criterion, n_epoch=n_epoch)\n",
    "        accuracy = test_with_dataloader(model=model, dataloader=test_dataloader)\n",
    "\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    return np.array(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277d03f",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d83dfc",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee55ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = load_samples_dataset(drug_type='Cannabis')\n",
    "full_dataset.shuffle()\n",
    "dataset_X, dataset_y = full_dataset.get_row_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.matrix(dataset_X)\n",
    "matrix = matrix\n",
    "print(f'Matrix shape : {matrix.shape}.')\n",
    "\n",
    "bin_matrix = matrix.copy()\n",
    "bin_matrix[bin_matrix > 0] = 1\n",
    "\n",
    "plot_matrix = bin_matrix[:500,:].T\n",
    "\n",
    "matfig = plt.figure(figsize=(20,4))\n",
    "plt.matshow(plot_matrix, fignum=matfig.number)\n",
    "plt.title('Subset of instances')\n",
    "plt.xlabel('Instances')\n",
    "plt.ylabel('Instances variables')\n",
    "plt.show()\n",
    "\n",
    "sparsisty = np.count_nonzero(matrix == 0) / matrix.size\n",
    "print(f'Matrix is {100 * sparsisty:3.2f}% sparse')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b05377",
   "metadata": {},
   "source": [
    "## Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28281840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "\n",
    "n_input = len(dataset_X[0])\n",
    "n_hidden = math.floor(n_input / 2)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_input, n_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(n_hidden, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "model = model.float()\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print(f'Model: {model}')\n",
    "print(f'Model on device : {next(model.parameters()).device}.')\n",
    "\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a831f4cc",
   "metadata": {},
   "source": [
    "## Perfoming cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd0a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7\n",
    "accuracies = cross_valisation(model=model, X=dataset_X, y=dataset_y, optimizer=optimizer, criterion=criterion, k=k, n_epoch=20)\n",
    "print(f'Accuracy mean : {accuracies.mean()}')\n",
    "print(f'Accuracy standard deviation : {accuracies.std()}')\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Accuracy for each cross-validation iteration')\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Score')\n",
    "plt.plot(range(1, k + 1), accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
